{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2fa185-a00b-41e7-b9cc-dd242397126a",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccec353-e1ad-401a-b8ea-534bb8f102b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# JSON vs TOON-like: Token Efficiency Mini Experiment\n",
    "\n",
    "**Author:** Cristina Varas Menadas  \n",
    "\n",
    "This notebook explores how different input formats impact token usage for Large Language Models (LLMs), using a simple synthetic dataset of user records. The goal is not to perfectly replicate the TOON spec, but to get a **practical, data-driven feel** for:\n",
    "\n",
    "- How much more verbose **pretty-printed JSON** is compared to other options.\n",
    "- How much we can gain just by using **minified JSON**.\n",
    "- How a **TOON-like, tabular format** can further reduce token count for uniform, structured data.\n",
    "\n",
    "### What this notebook does\n",
    "\n",
    "- Generates fake user data (id, name, country, purchases, segment).\n",
    "- Encodes the same data in three formats:\n",
    "  - JSON (pretty-printed, human-friendly).\n",
    "  - JSON (minified, no extra whitespace).\n",
    "  - A simple **TOON-like** format: `users[N]{cols}:\\nvalues...`\n",
    "- Uses the `cl100k_base` tokenizer (compatible with many OpenAI models) to measure:\n",
    "  - Token counts per format.\n",
    "  - Character counts per format.\n",
    "- Compares token savings of:\n",
    "  - TOON-like vs pretty JSON.\n",
    "  - TOON-like vs minified JSON.\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "There is a lot of buzz around new LLM-oriented formats like TOON that claim **30–60% token savings** compared to JSON.  \n",
    "This notebook helps answer a more grounded question:\n",
    "\n",
    "> *“How much do I really gain in practice, and how much can I already save just by cleaning up my JSON and prompts?”*\n",
    "\n",
    "Use this as a small, reproducible experiment to support discussions or articles on **LLM cost optimization**, **prompt design**, and **data formats** for AI workloads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395782dc-806f-4aaa-ac27-1e731c52f545",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b1426e8-e6bd-475b-95bf-0d85ca18612b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: pandas in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/datascience/conda/generalml_p311_cpu_x86_64_v1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b6cc5-4361-4d86-899b-921c50f8340d",
   "metadata": {},
   "source": [
    "## 2. Imports, tokenizer, and helper to count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3693a7-b894-4a0b-99f1-a06651b45cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "# Use the tokenizer compatible with many OpenAI models (e.g. cl100k_base)\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Count tokens using the cl100k_base tokenizer.\"\"\"\n",
    "    return len(enc.encode(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e37bc-c5ec-4386-818b-50e56184e775",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Generate sample user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b0fe992-9688-4498-a586-4a211bdc9431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'name': 'User 1',\n",
       "  'country': 'DE',\n",
       "  'purchases': 8,\n",
       "  'segment': 'standard'},\n",
       " {'id': 2,\n",
       "  'name': 'User 2',\n",
       "  'country': 'FR',\n",
       "  'purchases': 38,\n",
       "  'segment': 'churn_risk'},\n",
       " {'id': 3,\n",
       "  'name': 'User 3',\n",
       "  'country': 'IT',\n",
       "  'purchases': 27,\n",
       "  'segment': 'new'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_users(n_rows: int):\n",
    "    \"\"\"\n",
    "    Generate a list of dictionaries with fake user data.\n",
    "    This simulates a typical payload you might send to an LLM:\n",
    "    users, purchases, country, segment, etc.\n",
    "    \"\"\"\n",
    "    countries = [\"ES\", \"FR\", \"DE\", \"IT\", \"UK\", \"PL\"]\n",
    "    segments = [\"standard\", \"vip\", \"new\", \"churn_risk\"]\n",
    "\n",
    "    data = []\n",
    "    for i in range(1, n_rows + 1):\n",
    "        user = {\n",
    "            \"id\": i,\n",
    "            \"name\": f\"User {i}\",\n",
    "            \"country\": random.choice(countries),\n",
    "            \"purchases\": random.randint(0, 50),\n",
    "            \"segment\": random.choice(segments),\n",
    "        }\n",
    "        data.append(user)\n",
    "    return data\n",
    "\n",
    "# Quick sanity check\n",
    "sample_data = generate_users(3)\n",
    "sample_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8ba37-149c-4d8f-9d48-b16d2531d1fd",
   "metadata": {},
   "source": [
    "## 4. JSON pretty, JSON minified, and TOON-like representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37a33f6-2428-411f-8108-95208ab1f00f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users[3]{id,name,country,purchases,segment}:\n",
      "1,User 1,DE,8,standard\n",
      "2,User 2,FR,38,churn_risk\n",
      "3,User 3,IT,27,new\n"
     ]
    }
   ],
   "source": [
    "def to_json_pretty(data):\n",
    "    \"\"\"Return JSON with indentation (human-readable).\"\"\"\n",
    "    return json.dumps(data, indent=2, ensure_ascii=False)\n",
    "\n",
    "def to_json_minified(data):\n",
    "    \"\"\"Return minified JSON (no unnecessary spaces or newlines).\"\"\"\n",
    "    return json.dumps(data, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "\n",
    "def to_toon_like(data, root_name=\"users\"):\n",
    "    \"\"\"\n",
    "    Create a simple TOON-like representation:\n",
    "\n",
    "    users[N]{col1,col2,...}:\n",
    "      v1,v2,...\n",
    "      v1,v2,...\n",
    "\n",
    "    Assumes a list of dicts with the same keys.\n",
    "    This is not a full official TOON implementation, but it is\n",
    "    close enough to illustrate the idea: a compact, tabular format\n",
    "    for LLM prompts.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return \"\"\n",
    "\n",
    "    keys = list(data[0].keys())\n",
    "    header = f\"{root_name}[{len(data)}]{{{','.join(keys)}}}:\"\n",
    "\n",
    "    lines = [header]\n",
    "\n",
    "    for row in data:\n",
    "        values = []\n",
    "        for k in keys:\n",
    "            v = row[k]\n",
    "            if isinstance(v, str):\n",
    "                # Very basic escaping for commas and quotes\n",
    "                s = v.replace('\"', '\"\"')\n",
    "                if \",\" in s:\n",
    "                    s = f'\"{s}\"'\n",
    "                values.append(s)\n",
    "            else:\n",
    "                values.append(str(v))\n",
    "        lines.append(\",\".join(values))\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Quick example\n",
    "toon_example = to_toon_like(sample_data)\n",
    "print(toon_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22254efe-c936-43e2-8195-158a7f28da17",
   "metadata": {},
   "source": [
    "## 5.Visual comparison: JSON vs TOON-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e0f34d-6b8e-4500-a3c1-49fafd820cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== JSON pretty ===\n",
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"name\": \"User 1\",\n",
      "    \"country\": \"DE\",\n",
      "    \"purchases\": 8,\n",
      "    \"segment\": \"standard\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"name\": \"User 2\",\n",
      "    \"country\": \"FR\",\n",
      "    \"purchases\": 38,\n",
      "    \"segment\": \"churn_risk\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"name\": \"User 3\",\n",
      "    \"country\": \"IT\",\n",
      "    \"purchases\": 27,\n",
      "    \"segment\": \"new\"\n",
      "  }\n",
      "] ...\n",
      "\n",
      "=== JSON minified ===\n",
      "[{\"id\":1,\"name\":\"User 1\",\"country\":\"DE\",\"purchases\":8,\"segment\":\"standard\"},{\"id\":2,\"name\":\"User 2\",\"country\":\"FR\",\"purchases\":38,\"segment\":\"churn_risk\"},{\"id\":3,\"name\":\"User 3\",\"country\":\"IT\",\"purchases\":27,\"segment\":\"new\"}] ...\n",
      "\n",
      "=== TOON-like ===\n",
      "users[3]{id,name,country,purchases,segment}:\n",
      "1,User 1,DE,8,standard\n",
      "2,User 2,FR,38,churn_risk\n",
      "3,User 3,IT,27,new ...\n"
     ]
    }
   ],
   "source": [
    "json_pretty_example = to_json_pretty(sample_data)\n",
    "json_min_example = to_json_minified(sample_data)\n",
    "\n",
    "print(\"=== JSON pretty ===\")\n",
    "print(json_pretty_example[:400], \"...\\n\")\n",
    "\n",
    "print(\"=== JSON minified ===\")\n",
    "print(json_min_example[:400], \"...\\n\")\n",
    "\n",
    "print(\"=== TOON-like ===\")\n",
    "print(toon_example[:400], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb39572-727a-4aa0-9cf8-20f784388889",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Run the experiment: tokens and characters for different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "825a54d6-d0c5-47d4-acda-1eb1e684dbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>json_pretty_tokens</th>\n",
       "      <th>json_minified_tokens</th>\n",
       "      <th>toon_tokens</th>\n",
       "      <th>json_pretty_chars</th>\n",
       "      <th>json_minified_chars</th>\n",
       "      <th>toon_chars</th>\n",
       "      <th>toon_vs_pretty_%</th>\n",
       "      <th>toon_vs_minified_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>434</td>\n",
       "      <td>245</td>\n",
       "      <td>140</td>\n",
       "      <td>1115</td>\n",
       "      <td>754</td>\n",
       "      <td>278</td>\n",
       "      <td>67.741935</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4277</td>\n",
       "      <td>2378</td>\n",
       "      <td>1236</td>\n",
       "      <td>11165</td>\n",
       "      <td>7564</td>\n",
       "      <td>2409</td>\n",
       "      <td>71.101239</td>\n",
       "      <td>48.023549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>42808</td>\n",
       "      <td>23809</td>\n",
       "      <td>12282</td>\n",
       "      <td>113699</td>\n",
       "      <td>77698</td>\n",
       "      <td>25744</td>\n",
       "      <td>71.309101</td>\n",
       "      <td>48.414465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>221700</td>\n",
       "      <td>126701</td>\n",
       "      <td>69285</td>\n",
       "      <td>576868</td>\n",
       "      <td>396867</td>\n",
       "      <td>136913</td>\n",
       "      <td>68.748309</td>\n",
       "      <td>45.316138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rows  json_pretty_tokens  json_minified_tokens  toon_tokens  \\\n",
       "0    10                 434                   245          140   \n",
       "1   100                4277                  2378         1236   \n",
       "2  1000               42808                 23809        12282   \n",
       "3  5000              221700                126701        69285   \n",
       "\n",
       "   json_pretty_chars  json_minified_chars  toon_chars  toon_vs_pretty_%  \\\n",
       "0               1115                  754         278         67.741935   \n",
       "1              11165                 7564        2409         71.101239   \n",
       "2             113699                77698       25744         71.309101   \n",
       "3             576868               396867      136913         68.748309   \n",
       "\n",
       "   toon_vs_minified_%  \n",
       "0           42.857143  \n",
       "1           48.023549  \n",
       "2           48.414465  \n",
       "3           45.316138  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_experiment(row_counts=(10, 100, 1000)):\n",
    "    \"\"\"\n",
    "    For each number of rows, generate fake users and compare:\n",
    "      - JSON pretty\n",
    "      - JSON minified\n",
    "      - TOON-like\n",
    "\n",
    "    We measure:\n",
    "      - token counts\n",
    "      - character counts\n",
    "      - relative token savings of TOON vs JSON pretty and minified\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for n in row_counts:\n",
    "        data = generate_users(n)\n",
    "\n",
    "        json_pretty = to_json_pretty(data)\n",
    "        json_minified = to_json_minified(data)\n",
    "        toon_text = to_toon_like(data)\n",
    "\n",
    "        row_result = {\n",
    "            \"rows\": n,\n",
    "            \"json_pretty_tokens\": count_tokens(json_pretty),\n",
    "            \"json_minified_tokens\": count_tokens(json_minified),\n",
    "            \"toon_tokens\": count_tokens(toon_text),\n",
    "            \"json_pretty_chars\": len(json_pretty),\n",
    "            \"json_minified_chars\": len(json_minified),\n",
    "            \"toon_chars\": len(toon_text),\n",
    "        }\n",
    "        results.append(row_result)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Relative savings (percentage)\n",
    "    df[\"toon_vs_pretty_%\"] = (1 - df[\"toon_tokens\"] / df[\"json_pretty_tokens\"]) * 100\n",
    "    df[\"toon_vs_minified_%\"] = (1 - df[\"toon_tokens\"] / df[\"json_minified_tokens\"]) * 100\n",
    "\n",
    "    return df\n",
    "\n",
    "df_results = run_experiment(row_counts=(10, 100, 1000, 5000))\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e509b9-f0c1-4961-af00-16f4394f69a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10\n",
      "  JSON pretty   : 434.0 tokens\n",
      "  JSON minified : 245.0 tokens\n",
      "  TOON-like     : 140.0 tokens\n",
      "  TOON vs pretty   : 67.7% fewer tokens\n",
      "  TOON vs minified : 42.9% fewer tokens\n",
      "\n",
      "Rows: 100\n",
      "  JSON pretty   : 4277.0 tokens\n",
      "  JSON minified : 2378.0 tokens\n",
      "  TOON-like     : 1236.0 tokens\n",
      "  TOON vs pretty   : 71.1% fewer tokens\n",
      "  TOON vs minified : 48.0% fewer tokens\n",
      "\n",
      "Rows: 1000\n",
      "  JSON pretty   : 42808.0 tokens\n",
      "  JSON minified : 23809.0 tokens\n",
      "  TOON-like     : 12282.0 tokens\n",
      "  TOON vs pretty   : 71.3% fewer tokens\n",
      "  TOON vs minified : 48.4% fewer tokens\n",
      "\n",
      "Rows: 5000\n",
      "  JSON pretty   : 221700.0 tokens\n",
      "  JSON minified : 126701.0 tokens\n",
      "  TOON-like     : 69285.0 tokens\n",
      "  TOON vs pretty   : 68.7% fewer tokens\n",
      "  TOON vs minified : 45.3% fewer tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_summary(df):\n",
    "    \"\"\"\n",
    "    Print a human-readable summary of the experiment\n",
    "    that you can reuse in your article.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"Rows: {int(row['rows'])}\")\n",
    "        print(f\"  JSON pretty   : {row['json_pretty_tokens']} tokens\")\n",
    "        print(f\"  JSON minified : {row['json_minified_tokens']} tokens\")\n",
    "        print(f\"  TOON-like     : {row['toon_tokens']} tokens\")\n",
    "        print(f\"  TOON vs pretty   : {row['toon_vs_pretty_%']:.1f}% fewer tokens\")\n",
    "        print(f\"  TOON vs minified : {row['toon_vs_minified_%']:.1f}% fewer tokens\")\n",
    "        print()\n",
    "\n",
    "print_summary(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06418f1e-aeec-41c5-9d47-47cccfbe5abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p311_cpu_x86_64_v1]",
   "language": "python",
   "name": "conda-env-generalml_p311_cpu_x86_64_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
